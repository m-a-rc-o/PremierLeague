{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2238526598500211",
   "metadata": {},
   "source": [
    "## Searching patterns\n",
    "Can we predict a team's final position in the league on the basis of the number of goals *scored* by the team during the season?\n",
    "What about the goals *conceded*? Can we infer a relationship between these two predictors (*GoalsScored* and *GoalsConceded*) and the response, i.e. the *Points*?\n",
    "\n",
    "Let's take a closer look to our data."
   ]
  },
  {
   "cell_type": "code",
   "id": "bc8b5e22f0812f2",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "from mysql_connection import mysql_engine\n",
    "\n",
    "# Define the query\n",
    "query = (\"SELECT fp.SeasonID, fp.Season, fp.Team, fp.Points, fp.GoalsScored, fp.GoalsConceded, fp.Position, pvp.PointsPerWin, \"\n",
    "         \"CASE WHEN Position BETWEEN 1 AND 2 THEN '1st-2nd' WHEN Position BETWEEN 3 AND 5 THEN '3rd-5th' WHEN Position BETWEEN 6 AND 10 THEN '6th-10th' \"\n",
    "         \"ELSE '11th-last place' END AS Classified FROM FinalPositions AS fp JOIN PointsVsPositions AS pvp ON fp.SeasonID = pvp.SeasonID\")\n",
    "\n",
    "# Define the DataFrame\n",
    "df = pd.read_sql(query, mysql_engine)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "cef0b5712a716e7c",
   "metadata": {},
   "source": [
    "Here we imported the relevant data into a pandas DataFrames named `df`. Remember that it is necessary to distinguish\n",
    "between seasons in which, respectively, two points or three points were assigned for each win."
   ]
  },
  {
   "cell_type": "code",
   "id": "46eff3a6b865b5b2",
   "metadata": {},
   "source": [
    "df.info()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "415687f08a74c77c",
   "metadata": {},
   "source": [
    "print(\"The are \" + str(df[df['PointsPerWin'] == 2].shape[0]) + \" entries where 'PointsPerWin' = 2. \")\n",
    "print(\"The are \" + str(df[df['PointsPerWin'] == 3].shape[0]) + \" entries where 'PointsPerWin' = 3. \")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "6e61468e0a1a5e19",
   "metadata": {},
   "source": [
    "`df` contains a total of 2563 entries, of which 1682 are relative to seasons in which *two* points were awarded to each win,\n",
    "while the remaining 881 are relative to seasons with *three* points assigned for each win.\n",
    "\n",
    "We can look at the scatter plots of *GoalsScored* vs *Points* and *GoalsConceded* vs *Points* to better understand the relationship\n",
    "between the variables."
   ]
  },
  {
   "cell_type": "code",
   "id": "8419b7e213e20b67",
   "metadata": {},
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set_style()\n",
    "\n",
    "sns.relplot(data=df, \n",
    "            x='GoalsScored',\n",
    "            y='Points',\n",
    "            col='PointsPerWin',\n",
    "            hue='Classified',\n",
    "            alpha=0.5,\n",
    "            kind='scatter')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "ae772aa881c156",
   "metadata": {},
   "source": [
    "sns.relplot(data=df, \n",
    "            x='GoalsConceded',\n",
    "            y='Points',\n",
    "            col='PointsPerWin',\n",
    "            hue='Classified',\n",
    "            alpha=0.5,\n",
    "            kind='scatter')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "These plots suggest that there may be a **linear relationship** between the predictors and the response.\n",
    "This can be clearly seen by looking at the data relative to seasons with three points per win,\n",
    "while the existence of a linear relationship between the predictors and the *Points* seems less evident in the plots where *PointsPerWin* = 2,\n",
    "especially if we consider the *GoalsConceded* variable."
   ],
   "id": "caf4690e7e1f36d5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### *GoalsScored* vs *Points*\n",
    "To analyze this relation quantitatively, we can fit a **linear regression** model to our data by using the *method of least squares*.\n",
    "We can begin by using a single predictor, for example *GoalsScored*:"
   ],
   "id": "e42026cf3b2b6ffc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data from the DataFrame\n",
    "# PointsPerWin = 2\n",
    "goals_scored_2 = df[df['PointsPerWin'] == 2].GoalsScored.to_frame()\n",
    "points_2 = df[df['PointsPerWin'] == 2].Points.to_frame()\n",
    "\n",
    "# PointsPerWin = 3\n",
    "goals_scored_3 = df[df['PointsPerWin'] == 3].GoalsScored.to_frame()\n",
    "points_3 = df[df['PointsPerWin'] == 3].Points.to_frame()\n",
    "\n",
    "# Split the data into training/testing sets\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(goals_scored_2, points_2)\n",
    "X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(goals_scored_3, points_3)\n",
    "\n",
    "# Create linear regression object and fit the training data\n",
    "scored_reg_2 = LinearRegression().fit(X_train_2, y_train_2)\n",
    "scored_reg_3 = LinearRegression().fit(X_train_3, y_train_3)"
   ],
   "id": "38d10dfcc100a38c",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's take a look at the coefficients of our model:",
   "id": "9016b292620f2145"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Calculate the predicted response for the training data\n",
    "y_train_2_pred = scored_reg_2.predict(X_train_2)\n",
    "y_train_3_pred = scored_reg_3.predict(X_train_3)\n",
    "\n",
    "# Summarize the results\n",
    "print(\"2 Points per win. Model: GoalsScored vs Points.\")\n",
    "print(\"\\nCoefficient of the model: \" + str(scored_reg_2.coef_[0][0]))\n",
    "print(\"Intercept: \" + str(scored_reg_2.intercept_[0]))\n",
    "print(\"The training mean squared error (MSE) is %.2f\" % mean_squared_error(y_train_2, y_train_2_pred))\n",
    "print(\"The R^2 score calculated on the training set is %.2f\" % r2_score(y_train_2, y_train_2_pred))\n",
    "print(\"\\n3 Points per win. Model: GoalsScored vs Points.\")\n",
    "print(\"\\nCoefficient of the model: \" + str(scored_reg_3.coef_[0][0]))\n",
    "print(\"Intercept: \" + str(scored_reg_3.intercept_[0]))\n",
    "print(\"The training mean squared error (MSE) is %.2f\" % mean_squared_error(y_train_3, y_train_3_pred))\n",
    "print(\"The R^2 score calculated on the training set is %.2f\" % r2_score(y_train_3, y_train_3_pred))"
   ],
   "id": "1d7d4d9c08fe1c06",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We can see that the model performs better on the data corresponding to seasons with three points awarded for each win, \n",
    "as the $R^2$ value is substantially higher in this case.\n",
    "Notice also that the value of the intercept in the model trained with the two points per win data seems highly unreasonable,\n",
    "as it would suggest that, on average, a team that scores no goals during the entire seasons would still finish the league with more than 16 points.\n",
    "These observations indicate that this simple model is not very accurate, and it should be rejected at least for the dataset relative to the seasons with 2 points per win.\n",
    "\n",
    "For a better evaluation of the model, however, we must analyze its performance on the test dataset:"
   ],
   "id": "1409579908b6d342"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calculate the predicted response for the testing data\n",
    "y_test_2_pred = scored_reg_2.predict(X_test_2)\n",
    "y_test_3_pred = scored_reg_3.predict(X_test_3)\n",
    "\n",
    "# Summarize the results\n",
    "print(\"2 Points per win. Model: GoalsScored vs Points.\")\n",
    "print(\"The testing mean squared error (MSE) is %.2f\" % mean_squared_error(y_test_2, y_test_2_pred))\n",
    "print(\"The R^2 score calculated on the testing set is %.2f\" % r2_score(y_test_2, y_test_2_pred))\n",
    "print(\"\\n3 Points per win. Model: GoalsScored vs Points.\")\n",
    "print(\"The testing mean squared error (MSE) is %.2f\" % mean_squared_error(y_test_3, y_test_3_pred))\n",
    "print(\"The R^2 score calculated on the testing set is %.2f\" % r2_score(y_test_3, y_test_3_pred))"
   ],
   "id": "56b939f199fdc429",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can see that, even after using a testing dataset, the scores of the model remain substantially unaltered.",
   "id": "361c41e065667d79"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### *GoalsConceded* vs *Points*\n",
    "We can now repeat the same analysis using the *GoalsConceded* as a predictor for the *Points*."
   ],
   "id": "ed35da35325744d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load data from the DataFrame\n",
    "# PointsPerWin = 2\n",
    "goals_conceded_2 = df[df['PointsPerWin'] == 2].GoalsConceded.to_frame()\n",
    "\n",
    "# PointsPerWin = 3\n",
    "goals_conceded_3 = df[df['PointsPerWin'] == 3].GoalsConceded.to_frame()\n",
    "\n",
    "# Split the data into training/testing sets\n",
    "XX_train_2, XX_test_2, yy_train_2, yy_test_2 = train_test_split(goals_conceded_2, points_2)\n",
    "XX_train_3, XX_test_3, yy_train_3, yy_test_3 = train_test_split(goals_conceded_3, points_3)\n",
    "\n",
    "# Create linear regression object and fit the training data\n",
    "conceded_reg_2 = LinearRegression().fit(XX_train_2, yy_train_2)\n",
    "conceded_reg_3 = LinearRegression().fit(XX_train_3, yy_train_3)\n",
    "\n",
    "# Calculate the predicted response for the training data\n",
    "yy_train_2_pred = conceded_reg_2.predict(XX_train_2)\n",
    "yy_train_3_pred = conceded_reg_3.predict(XX_train_3)\n",
    "\n",
    "# Calculate the predicted response for the testing data\n",
    "yy_test_2_pred = conceded_reg_2.predict(XX_test_2)\n",
    "yy_test_3_pred = conceded_reg_3.predict(XX_test_3)\n",
    "\n",
    "# Summarize the results\n",
    "print(\"2 Points per win. Model: GoalsConceded vs Points.\")\n",
    "print(\"\\nCoefficient of the model: \" + str(conceded_reg_2.coef_[0][0]))\n",
    "print(\"Intercept: \" + str(conceded_reg_2.intercept_[0]))\n",
    "print(\"The training mean squared error (MSE) is %.2f\" % mean_squared_error(yy_train_2, yy_train_2_pred))\n",
    "print(\"The R^2 score calculated on the training set is %.2f\" % r2_score(yy_train_2, yy_train_2_pred))\n",
    "print(\"\\nThe testing mean squared error (MSE) is %.2f\" % mean_squared_error(yy_test_2, yy_test_2_pred))\n",
    "print(\"The R^2 score calculated on the testing set is %.2f\" % r2_score(yy_test_2, yy_test_2_pred))\n",
    "print(\"\\n3 Points per win. Model: GoalsConceded vs Points.\")\n",
    "print(\"\\nCoefficient of the model: \" + str(conceded_reg_3.coef_[0][0]))\n",
    "print(\"Intercept: \" + str(conceded_reg_3.intercept_[0]))\n",
    "print(\"The training mean squared error (MSE) is %.2f\" % mean_squared_error(yy_train_3, yy_train_3_pred))\n",
    "print(\"The R^2 score calculated on the training set is %.2f\" % r2_score(yy_train_3, yy_train_3_pred))\n",
    "print(\"\\nThe testing mean squared error (MSE) is %.2f\" % mean_squared_error(yy_test_3, yy_test_3_pred))\n",
    "print(\"The R^2 score calculated on the testing set is %.2f\" % r2_score(yy_test_3, yy_test_3_pred))"
   ],
   "id": "6001a2a8416bf1cc",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "As we could expect, the coefficient of the regression line is negative: the fewer goals one team concedes, the more points it will obtain.\n",
    "When we train the model with the two points per win data, it achieves an extremely low $R^2$ score (10%); this was already clear when we first looked at the scatterplot of *GoalsConceded* vs *Points*.\n",
    "When we use the data relative to seasons with three points per win the model performs far better, achieving an $R^2$ score of 61%;\n",
    "this result, however, is not sufficient to conclude with certainty that a linear relationship exists."
   ],
   "id": "b8aa831599459871"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Multiple linear regression\n",
    "We can make one more attempt to find a linear relationship between the two predictors (*GoalsScored* and *GoalsConceded*) and the number of *Points* by fitting a multiple linear regression model."
   ],
   "id": "4fe67295360f5b6c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load data from the DataFrame\n",
    "# PointsPerWin = 2\n",
    "predictors_2 = df[df['PointsPerWin'] == 2][['GoalsScored', 'GoalsConceded']]\n",
    "\n",
    "# PointsPerWin = 3\n",
    "predictors_3 = df[df['PointsPerWin'] == 3][['GoalsScored', 'GoalsConceded']]\n",
    "\n",
    "# Split the data into training/testing sets\n",
    "multiple_X_train_2, multiple_X_test_2, multiple_y_train_2, multiple_y_test_2 = train_test_split(predictors_2, points_2)\n",
    "multiple_X_train_3, multiple_X_test_3, multiple_y_train_3, multiple_y_test_3 = train_test_split(predictors_3, points_3)\n",
    "\n",
    "# Create linear regression object and fit the training data\n",
    "multiple_reg_2 = LinearRegression().fit(multiple_X_train_2, multiple_y_train_2)\n",
    "multiple_reg_3 = LinearRegression().fit(multiple_X_train_3, multiple_y_train_3)\n",
    "\n",
    "# Calculate the predicted response for the training data\n",
    "multiple_y_train_2_pred = multiple_reg_2.predict(multiple_X_train_2)\n",
    "multiple_y_train_3_pred = multiple_reg_3.predict(multiple_X_train_3)\n",
    "\n",
    "# Calculate the predicted response for the testing data\n",
    "multiple_y_test_2_pred = multiple_reg_2.predict(multiple_X_test_2)\n",
    "multiple_y_test_3_pred = multiple_reg_3.predict(multiple_X_test_3)\n",
    "\n",
    "# Summarize the results\n",
    "print(\"2 Points per win. Model: (GoalsScored, GoalsConceded) vs Points.\")\n",
    "print(\"\\nCoefficients of the model:\")\n",
    "print(\"GoalsScored -> \" + str(multiple_reg_2.coef_[0][0]))\n",
    "print(\"GoalsConceded -> \" + str(multiple_reg_2.coef_[0][1]))\n",
    "print(\"Intercept -> \" + str(multiple_reg_2.intercept_[0]))\n",
    "print(\"The training mean squared error (MSE) is %.2f\" % mean_squared_error(multiple_y_train_2, multiple_y_train_2_pred))\n",
    "print(\"The R^2 score calculated on the training set is %.2f\" % r2_score(multiple_y_train_2, multiple_y_train_2_pred))\n",
    "print(\"\\nThe testing mean squared error (MSE) is %.2f\" % mean_squared_error(multiple_y_test_2, multiple_y_test_2_pred))\n",
    "print(\"The R^2 score calculated on the testing set is %.2f\" % r2_score(multiple_y_test_2, multiple_y_test_2_pred))\n",
    "print(\"\\n3 Points per win. Model: (GoalsScored, GoalsConceded) vs Points.\")\n",
    "print(\"\\nCoefficients of the model:\")\n",
    "print(\"GoalsScored -> \" + str(multiple_reg_3.coef_[0][0]))\n",
    "print(\"GoalsConceded -> \" + str(multiple_reg_3.coef_[0][1]))\n",
    "print(\"Intercept -> \" + str(multiple_reg_3.intercept_[0]))\n",
    "print(\"The training mean squared error (MSE) is %.2f\" % mean_squared_error(multiple_y_train_3, multiple_y_train_3_pred))\n",
    "print(\"The R^2 score calculated on the training set is %.2f\" % r2_score(multiple_y_train_3, multiple_y_train_3_pred))\n",
    "print(\"\\nThe testing mean squared error (MSE) is %.2f\" % mean_squared_error(multiple_y_test_3, multiple_y_test_3_pred))\n",
    "print(\"The R^2 score calculated on the testing set is %.2f\" % r2_score(multiple_y_test_3, multiple_y_test_3_pred))"
   ],
   "id": "3d6b6f2d35de72b6",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We see that the multiple linear regression model performs well on the 2 points per win test dataset, achieving an $R^2$ score of 71% that is substantially higher than both the models trained with a single predictor and tested on the analogous dataset (42% for *GoalsScored* vs *Points* and only 10% for *GoalsConceded* vs *Points*).\n",
    "The model performs even better when evaluated on the 3 points per win test dataset, achieving an $R^2$ of 91% versus the 74% of *GoalsScored* vs *Points* and the 61% of *GoalsConceded* vs *Points*. "
   ],
   "id": "388f77901bd1a496"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Test visualizations\n",
    "In this last section we plot some sample visualizations obtained using the functions defined in the file 'visualizations.py'."
   ],
   "id": "292641535d343e99"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### `pie_chart_results()`\n",
    "The function `pie_chart_results()` provides an overview of the results of a given team during its history in the league.\n",
    "The resulting chart illustrates the total number of wins, draws and losses of the team subdivided with respect to home matches and away matches.\n",
    "\n",
    "**Example**"
   ],
   "id": "dcd73784da6eb7e5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import visualizations as vis\n",
    "\n",
    "vis.pie_chart_results('Liverpool')"
   ],
   "id": "bf6efdd30e88f162",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### `show_positions()`\n",
    "The function `show_positions()` takes three required arguments: a list of teams, a start season and an end season. As a result, it generates a plot showing the positions of the given teams in the seasons between the period specified.\n",
    "`show_positions()` is a useful tool to compare the performance of two or more teams in a given period of time.\n",
    "\n",
    "**Example**"
   ],
   "id": "764a72cb456a550a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "vis.show_positions(['Manchester Utd', \n",
    "                    'Manchester City', \n",
    "                    'Chelsea', \n",
    "                    'Arsenal'],\n",
    "                   '1973/1974',\n",
    "                   '1991/1992')"
   ],
   "id": "ceb5df3a921b1a7f",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
